{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ab4c2a9",
   "metadata": {},
   "source": [
    "# Web scraping Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f228ec",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "\n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c61057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4ec93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver on chrome\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")   #webdriver uploaded into pythonnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d856ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the URL using webdriver\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6be2c8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"2b83e4dc9e9f0a571af4dc3dbf9040cd\", element=\"e1e57d29-acf6-4307-b68e-600f11107514\")>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using webdriver searching the web element of the required search bar \n",
    "search_job = driver.find_element_by_class_name(\"suggestor-input\")\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4dcee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering or passing the search attribute\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "749766cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"2b83e4dc9e9f0a571af4dc3dbf9040cd\", element=\"b55ab274-5a48-4fad-bfad-0728e9efdc95\")>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using webdriver finding the webelement of the required search element\n",
    "search_loc = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60b426b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering or passing the search attribute\n",
    "search_loc.send_keys('bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05b0342e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"2b83e4dc9e9f0a571af4dc3dbf9040cd\", element=\"454558c7-0da2-4ec8-93be-3fb9e96d34cc\")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using webvdriver clicking submit button using absolute xpath method\n",
    "submit_button = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "submit_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdcc3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_button.click()  #clicks the button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "949bd020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"2b83e4dc9e9f0a571af4dc3dbf9040cd\", element=\"480344c1-83a9-42d9-828f-08a15ef45bd4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2b83e4dc9e9f0a571af4dc3dbf9040cd\", element=\"e4ebeac2-edf0-498b-a88a-59cc1f05e044\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2b83e4dc9e9f0a571af4dc3dbf9040cd\", element=\"31ff78b7-5cab-44bc-89e6-bbd5e01b0cd1\")>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job_title, job_location, company_name, exp_required using relative xpath\n",
    "\n",
    "job_title_tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_title_tags[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b834fc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hiring For Data Analyst I(SQL & Python)', 'Senior Data Analyst II']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = []\n",
    "for i in job_title_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1920bd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"2b83e4dc9e9f0a571af4dc3dbf9040cd\", element=\"1f44aeee-93c7-4e63-8031-85163a6a6210\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2b83e4dc9e9f0a571af4dc3dbf9040cd\", element=\"e9a3f2af-ad36-45f8-bb66-02d0214ccc21\")>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#job_location\n",
    "job_loc_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "job_loc_tags[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "485e851c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru', 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_loc=[]\n",
    "for i in job_loc_tags:\n",
    "    job_loc.append(i.text)\n",
    "job_loc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5b7fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Company name, exp req\n",
    "comp_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "exp_req = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "813b4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists and filling them with concerned attributes\n",
    "comp_loc = []\n",
    "for i in comp_tags:\n",
    "    comp_loc.append(i.text)\n",
    "exp_required = []\n",
    "for i in exp_req:\n",
    "    exp_required.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64dc68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating lists with limit of ten items\n",
    "job_titles = job_title[0:10]\n",
    "job_locations = job_loc[0:10]\n",
    "comp_names = comp_loc[0:10]\n",
    "exp = exp_required[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9428755d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Analyst I(SQL &amp; Python)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Clario India Pvt Ltd</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst - Ads &amp; Promotion Platform...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring Data analyst with Pharma Background acr...</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>HCL</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Coordinator | Data Analyst | MS Excel | T...</td>\n",
       "      <td>Bangalore/Bengaluru(Sadashiva Nagar)</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Analyst - Flipkart Data science group</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0            Hiring For Data Analyst I(SQL & Python)   \n",
       "1                             Senior Data Analyst II   \n",
       "2                                Senior Data Analyst   \n",
       "3                             Senior Data Analyst II   \n",
       "4                             Senior Data Analyst II   \n",
       "5  Senior Data Analyst - Ads & Promotion Platform...   \n",
       "6  Hiring Data analyst with Pharma Background acr...   \n",
       "7  Data Coordinator | Data Analyst | MS Excel | T...   \n",
       "8    Lead Data Analyst - Flipkart Data science group   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "7               Bangalore/Bengaluru(Sadashiva Nagar)   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                 Company Name Experience  \n",
       "0                        Clario India Pvt Ltd    0-2 Yrs  \n",
       "1                                    Flipkart    3-6 Yrs  \n",
       "2                                    Flipkart    3-8 Yrs  \n",
       "3                                    Flipkart    2-4 Yrs  \n",
       "4                                    Flipkart    2-4 Yrs  \n",
       "5                                       Gojek    3-8 Yrs  \n",
       "6                                         HCL   6-11 Yrs  \n",
       "7  Inspiration Manpower Consultancy Pvt. Ltd.    4-7 Yrs  \n",
       "8                                    Flipkart    1-3 Yrs  \n",
       "9                                    Flipkart    1-2 Yrs  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe as per the requirement\n",
    "analysts_jobs = pd.DataFrame()\n",
    "analysts_jobs[\"Job Title\"]=job_titles\n",
    "analysts_jobs[\"Location\"]=job_locations\n",
    "analysts_jobs[\"Company Name\"]=comp_names\n",
    "analysts_jobs[\"Experience\"]=exp\n",
    "analysts_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8944ae4",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "\n",
    "You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00e7ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries and the webdriver is already defined/loaded\n",
    "#webdriver is assiged to \"driver\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "127d34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")  #assigning the webdriver to a variable\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)    #opening the URl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "43e6ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag1 = driver.find_element_by_class_name(\"suggestor-input\")   #finding the search element tags\n",
    "search_tag1.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66a0bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag2 = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_tag2.send_keys(\"Bangalore\")    #entering/passing the search input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "189cd2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using absolute xpath for finding the search button\n",
    "search_buton = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_buton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "79c3c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using relative xpath finding the job title tags and then scraping the job titles \n",
    "job_tit_tags= driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_titles1 = [] #creating empty list\n",
    "for i in job_tit_tags:\n",
    "    job_titles1.append(i.text)\n",
    "job_name=job_titles1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef3d6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using relative xpath finding the job location tags and then scraping the job locations \n",
    "job_loc_tags= driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "job_loc1 = [] #creating empty list\n",
    "for i in job_loc_tags:\n",
    "    job_loc1.append(i.text)\n",
    "job_locas=job_loc1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4b239a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using relative xpath finding the job location tags and then scraping the job locations \n",
    "job_comp_tags= driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "job_comp1 = [] #creating empty list\n",
    "for i in job_comp_tags:\n",
    "    job_comp1.append(i.text)\n",
    "job_company=job_comp1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "66ae2d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cabin Crew Airbus April'22</td>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Guwahati, Kolkata, Mumbai, Nagpur, New Delhi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urgent Opening For Permanent Work From Home - ...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>Noida, Kolkata, Pune, Lucknow, Ahmedabad, Amri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beauty Therapist</td>\n",
       "      <td>Kaya Skin Clinic</td>\n",
       "      <td>Kolkata, Mumbai, Delhi, Pune, Chennai, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urgent Requirement in DXC technology _Salesfor...</td>\n",
       "      <td>DXC Technology</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>React JS Developer | PAN India | Weekend Inter...</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Urgent Opening in DXC Technology - Java Developer</td>\n",
       "      <td>DXC Technology</td>\n",
       "      <td>Noida, Mumbai, Indore, Hyderabad/Secunderabad,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For International Voice process- Hydera...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Opening in DXC technology | Salesforce Lightni...</td>\n",
       "      <td>DXC Technology</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For HPOO</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Salesforce CPQ Lightning Developer</td>\n",
       "      <td>DXC Technology</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title      Company Name  \\\n",
       "0                         Cabin Crew Airbus April'22            IndiGo   \n",
       "1  Urgent Opening For Permanent Work From Home - ...     Tech Mahindra   \n",
       "2                                   Beauty Therapist  Kaya Skin Clinic   \n",
       "3  Urgent Requirement in DXC technology _Salesfor...    DXC Technology   \n",
       "4  React JS Developer | PAN India | Weekend Inter...           Mphasis   \n",
       "5  Urgent Opening in DXC Technology - Java Developer    DXC Technology   \n",
       "6  Hiring For International Voice process- Hydera...     Tech Mahindra   \n",
       "7  Opening in DXC technology | Salesforce Lightni...    DXC Technology   \n",
       "8                                    Hiring For HPOO             Wipro   \n",
       "9                 Salesforce CPQ Lightning Developer    DXC Technology   \n",
       "\n",
       "                                            Location  \n",
       "0  Guwahati, Kolkata, Mumbai, Nagpur, New Delhi, ...  \n",
       "1  Noida, Kolkata, Pune, Lucknow, Ahmedabad, Amri...  \n",
       "2   Kolkata, Mumbai, Delhi, Pune, Chennai, Bengaluru  \n",
       "3  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...  \n",
       "4  Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...  \n",
       "5  Noida, Mumbai, Indore, Hyderabad/Secunderabad,...  \n",
       "6  Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...  \n",
       "7  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...  \n",
       "8  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...  \n",
       "9  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a DataFrame as per the requirement\n",
    "scientist = pd.DataFrame()\n",
    "scientist[\"Job Title\"]=job_name\n",
    "scientist[\"Company Name\"]=job_company\n",
    "scientist[\"Location\"]=job_locas\n",
    "scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec87b6",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "        You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "571535ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")  #assigning the webdriver to a variable\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)    #opening the URl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4b836dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_ds = driver.find_element_by_class_name(\"suggestor-input\")   #finding the search element tags\n",
    "search_ds.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6648fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using absolute xpath for finding the search button\n",
    "search_b = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f4bf77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying location filter\n",
    "loc_filter_tags = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i\")\n",
    "loc_filter_tags.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ed05487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying Salary Filter\n",
    "sal_fil_tags = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i\")\n",
    "sal_fil_tags\n",
    "sal_fil_tags.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b7c64baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping job-title, job-location, company name, experience required of first 10 jobs using relative xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "33298db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"61030ffe93c5cfe770c64ff055d1173a\", element=\"f718694a-2b96-4222-aa67-5eb523d34029\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"61030ffe93c5cfe770c64ff055d1173a\", element=\"03806c17-a614-4fd8-82d1-81887d2fbe66\")>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_tags=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "ds_tags[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d631cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_tit =[] #creating empty list\n",
    "for i in ds_tags:\n",
    "    job_tit.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f976bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cm_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "ds_exp_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "ds_loc_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5a6233cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tits=[]\n",
    "for i in ds_cm_tags:\n",
    "    comp_tits.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e8313a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tits =[]\n",
    "for i in ds_exp_tags:\n",
    "    exp_tits.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "02f8c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tits =[]\n",
    "for i in ds_loc_tags:\n",
    "    loc_tits.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fadcc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_tits = job_tit[0:10]\n",
    "comp_tits=comp_tits[0:10]\n",
    "exp_tits=exp_tits[0:10]\n",
    "loc_tits=loc_tits[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "051b16ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent Opportunity For Freshers For AI/ML, ...</td>\n",
       "      <td>NTT Data</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst / Data Scientist / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, New Delhi, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Senior Data Scientist-Noida</td>\n",
       "      <td>Lumiq.ai</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Noida, New Delhi, Greater Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data scientist- Python</td>\n",
       "      <td>TeamPlus Staffing Solution Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Analyst/ Scientist- Fresher Position</td>\n",
       "      <td>Sejal Consulting Hub</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist _NLP</td>\n",
       "      <td>EXL</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR\\n(WFH during ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Only Fresher / Python Data Scientist / Trainee...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Indihire HR Consultants Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Delhi / NCR\\n(WFH during Covid)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Excellent Opportunity For Freshers For AI/ML, ...   \n",
       "1  Data Analyst / Data Scientist / Business Analy...   \n",
       "2             Hiring For Senior Data Scientist-Noida   \n",
       "3                             Data scientist- Python   \n",
       "4   Junior Data Analyst/ Scientist- Fresher Position   \n",
       "5                                Data Scientist _NLP   \n",
       "6                     Data Scientist - MIND Infotech   \n",
       "7                     Data Scientist - MIND Infotech   \n",
       "8  Only Fresher / Python Data Scientist / Trainee...   \n",
       "9                                Lead Data Scientist   \n",
       "\n",
       "                                    Company Experience  \\\n",
       "0                                  NTT Data    0-0 Yrs   \n",
       "1                 GABA Consultancy services    0-0 Yrs   \n",
       "2                                  Lumiq.ai    2-6 Yrs   \n",
       "3        TeamPlus Staffing Solution Pvt Ltd    3-6 Yrs   \n",
       "4                      Sejal Consulting Hub    0-3 Yrs   \n",
       "5                                       EXL    3-8 Yrs   \n",
       "6  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    4-8 Yrs   \n",
       "7  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    4-8 Yrs   \n",
       "8                 GABA Consultancy services    0-0 Yrs   \n",
       "9   Indihire HR Consultants Private Limited    2-4 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...  \n",
       "1                      Noida, New Delhi, Delhi / NCR  \n",
       "2                    Noida, New Delhi, Greater Noida  \n",
       "3                                   Gurgaon/Gurugram  \n",
       "4  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "5  Bangalore/Bengaluru, Delhi / NCR\\n(WFH during ...  \n",
       "6                                              Noida  \n",
       "7                                              Noida  \n",
       "8                 Noida, New Delhi, Gurgaon/Gurugram  \n",
       "9                    Delhi / NCR\\n(WFH during Covid)  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating data frame as per requirement\n",
    "ds_dataframe = pd.DataFrame()\n",
    "ds_dataframe[\"Job Title\"]=job_tits\n",
    "ds_dataframe[\"Company\"]=comp_tits\n",
    "ds_dataframe[\"Experience\"]=exp_tits\n",
    "ds_dataframe[\"Location\"]=loc_tits\n",
    "ds_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3cbbe",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aae880ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bce5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for closing the pop up that occured\n",
    "close = driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button\")\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68ac125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tag = driver.find_element_by_class_name(\"_3704LK\")   #finding the search element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50d7285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tag.send_keys(\"Sunglasses\")    #passing the variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1784e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81d95402",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag.click()   #clicking the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98177520",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list = []\n",
    "product_des = []\n",
    "price = []\n",
    "#for navigating through three pages to scrape the brand names\n",
    "for page in range(1,4,1):\n",
    "    page_url=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    for i in range(len(brand)):\n",
    "        brand_list.append(brand[i].text)\n",
    "#for navigating through three pages to scrape the prod description        \n",
    "for page in range(1,4,1):\n",
    "    page_url=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    product =driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for i in range(len(product)):\n",
    "        product_des.append(product[i].text)\n",
    "#for navigating through three pages to scrape the price\n",
    "for page in range(1,4,1):\n",
    "    page_url=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    price1 = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for i in range(len(brand)):\n",
    "        price.append(price1[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97f289fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we make a data frame to display the details of first 100 products\n",
    "sunglasses = pd.DataFrame()\n",
    "sunglasses[\"Name\"] = brand_list[0:100]\n",
    "sunglasses[\"Description\"]=product_des[0:100]\n",
    "sunglasses[\"Price\"]=price[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7d214c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (55)</td>\n",
       "      <td>₹198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Gradient Round Sunglasses (54)</td>\n",
       "      <td>₹229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹1,229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>Gradient Round Sunglasses (54)</td>\n",
       "      <td>₹284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name                                        Description   Price\n",
       "0         PIRASO              UV Protection Cat-eye Sunglasses (55)    ₹198\n",
       "1        Ray-Ban                     Gradient Round Sunglasses (54)    ₹229\n",
       "2           SRPM             UV Protection Wayfarer Sunglasses (50)    ₹253\n",
       "3         SUNBEE              UV Protection Aviator Sunglasses (54)    ₹229\n",
       "4         PIRASO  UV Protection, Polarized Wayfarer Sunglasses (...    ₹258\n",
       "..           ...                                                ...     ...\n",
       "95      Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹719\n",
       "96        PIRASO  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹250\n",
       "97     New Specs              UV Protection Aviator Sunglasses (54)    ₹238\n",
       "98      Fastrack         UV Protection Round Sunglasses (Free Size)  ₹1,229\n",
       "99  Silver Kartz                     Gradient Round Sunglasses (54)    ₹284\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6715fd2",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "       \n",
    "       When you will open the above link you will reach to the below shown webpage .\n",
    "        \n",
    "        As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "58cc30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")    #running webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a736f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "driver.get(url1)\n",
    "#Opening the URl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "89932a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"eac80fa9813c14b973b42d8eaab510ac\", element=\"3fd5fbe7-c753-4fa3-997e-582777ac2a47\")>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opening the reviews page by clicking show all reviews using absolute xpath\n",
    "show_all = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div/div/div[5]/div/a/div/span\")\n",
    "show_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "160e8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all.click()  #clicking the option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bd487116",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list=[]     #Creating an empty list for storing ratings\n",
    "#creating a for loop with range function for passing upto 12 pages\n",
    "#defining the URL and then fetching the page using dribver.get()\n",
    "#finding the rating tags on the page and using for loop to fill in the values to the list\n",
    "\n",
    "for page in range(1,13):\n",
    "    page_url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    rating = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in range(len(rating)):\n",
    "        rating_list.append(rating[i].text)\n",
    "\n",
    "rev_summary=[]\n",
    "for page in range(1,13):\n",
    "    page_url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    review = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    for i in range(len(review)):\n",
    "        rev_summary.append(review[i].text)\n",
    "        \n",
    "full_rev = []\n",
    "for page in range(1,13):\n",
    "    page_url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    full_revi = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    for i in range(len(full_revi)):\n",
    "        full_rev.append(full_revi[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "19fef1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating required data frame\n",
    "iphone=pd.DataFrame()\n",
    "iphone[\"Rating\"]=rating_list[0:100]\n",
    "iphone[\"Review\"]=rev_summary[0:100]\n",
    "iphone[\"Full Review\"]=full_rev[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d199e468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Not mere a phone , Its more than that for fun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice 👌👌👌👌👌👌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>MD sufiyan rider Owsm\\nMobile nd battery mast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Ok, so after almost 3 years I am again back in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>If you are looking for a premium phone under 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating               Review  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5            Just wow!   \n",
       "96      5     Perfect product!   \n",
       "97      5            Fabulous!   \n",
       "98      5            Wonderful   \n",
       "99      4         Nice product   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Not mere a phone , Its more than that for fun ...  \n",
       "96                                        Nice 👌👌👌👌👌👌  \n",
       "97  MD sufiyan rider Owsm\\nMobile nd battery mast ...  \n",
       "98  Ok, so after almost 3 years I am again back in...  \n",
       "99  If you are looking for a premium phone under 5...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f80016",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f9b68692",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url2=\"https://www.flipkart.com/\"\n",
    "driver.get(url2)  #getting the ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e0d46070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for closing the pop up that occured\n",
    "close = driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button\")\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9960dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for passing the search attribute\n",
    "input_tag = driver.find_element_by_class_name(\"_3704LK\")   #finding the search element\n",
    "input_tag.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bb4423be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for searching\n",
    "search_tag = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_tag.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c4935f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding all the required element tags and finding the requiured attributes\n",
    "brand_name = []\n",
    "for page in range(1,4,1):\n",
    "    page_url = \"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    for i in range(len(brand)):\n",
    "        brand_name.append(brand[i].text)\n",
    "\n",
    "product_des=[]\n",
    "for page in range(1,4,1):\n",
    "    page_url = \"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    product = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for i in range(len(product)):\n",
    "        product_des.append(product[i].text)\n",
    "        \n",
    "price_sneak=[]\n",
    "for page in range(1,4,1):\n",
    "    page_url = \"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for i in range(len(price)):\n",
    "        price_sneak.append(price[i].text)\n",
    "\n",
    "discount=[]\n",
    "for page in range(1,4,1):\n",
    "    page_url = \"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(page)\n",
    "    driver.get(page_url)\n",
    "    discount1 = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in range(len(discount1)):\n",
    "        discount.append(discount1[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "aedb3b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KWIK FIT</td>\n",
       "      <td>Kwik FIT casual sneaker shoes and partywear sh...</td>\n",
       "      <td>₹397</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noztile</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹448</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹649</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹341</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Navtrend</td>\n",
       "      <td>CR-1 Sneakers For Men</td>\n",
       "      <td>₹429</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>Flex R Dual Sneakers For Men</td>\n",
       "      <td>₹1,871</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>WHITEHUB</td>\n",
       "      <td>Casual Sneakers Shoes for Men Pack of 5 Combo(...</td>\n",
       "      <td>₹479</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Echor Men's Sneakers Fashion Lightweight Runni...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>corsac</td>\n",
       "      <td>Fashionable sneaker shoes Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name                                        Description  \\\n",
       "0          KWIK FIT  Kwik FIT casual sneaker shoes and partywear sh...   \n",
       "1           Noztile                                   Sneakers For Men   \n",
       "2          Magnolia                                   Sneakers For Men   \n",
       "3            Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...   \n",
       "4                TR                                   Sneakers For Men   \n",
       "..              ...                                                ...   \n",
       "95         Navtrend                              CR-1 Sneakers For Men   \n",
       "96  U.S. POLO ASSN.                       Flex R Dual Sneakers For Men   \n",
       "97         WHITEHUB  Casual Sneakers Shoes for Men Pack of 5 Combo(...   \n",
       "98         Magnolia  Echor Men's Sneakers Fashion Lightweight Runni...   \n",
       "99           corsac         Fashionable sneaker shoes Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹397  80% off  \n",
       "1     ₹399  80% off  \n",
       "2     ₹448  55% off  \n",
       "3     ₹649  59% off  \n",
       "4     ₹341  65% off  \n",
       "..     ...      ...  \n",
       "95    ₹429  37% off  \n",
       "96  ₹1,871  52% off  \n",
       "97    ₹479  60% off  \n",
       "98    ₹399  70% off  \n",
       "99    ₹449  55% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making df as per the requirement\n",
    "sneakers =  pd.DataFrame()\n",
    "sneakers[\"Name\"]=brand_name[0:100]\n",
    "sneakers[\"Description\"]=product_des[0:100]\n",
    "sneakers[\"Price\"]=price_sneak[0:100]\n",
    "sneakers[\"Discount\"]=discount[0:100]\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762b7871",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "        \n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image.\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "331f7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "urlm=\"https://www.myntra.com/shoes\"\n",
    "driver.get(urlm)  #getting the ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "4f0e747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting black color using absolute xpath\n",
    "black = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "black.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "fefd9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the price filter\n",
    "price_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "5e40557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists\n",
    "#defining the element tags and then making a for loop to fill in the values to list\n",
    "#after the 3 requried element tagss are defined and filled in using for loop defining 'click' to next page using relative xpath\n",
    "brand2=[]\n",
    "prod2=[]\n",
    "price2=[]\n",
    "for page in range(5):\n",
    "    brand_data=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "    for n in range(len(brand_data)):\n",
    "        brand2.append(brand_data[n].text)\n",
    "    prod_data=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    for m in range(len(prod_data)):\n",
    "        prod2.append(prod_data[m].text)\n",
    "    price_data=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "    for k in range(len(price_data)):\n",
    "        price2.append(price_data[k].text)\n",
    "    nextpage=driver.find_element_by_xpath('//li[@class=\"pagination-number\"]')    #this is  to goto the nextpage using RXPATH\n",
    "    nextpage.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "672c04c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Formal Leather Derby</td>\n",
       "      <td>Rs. 7990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>PU Block Pumps with Buckles</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Textured PU Block Pumps</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Solid Formal Oxfords</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Party Block Mules</td>\n",
       "      <td>Rs. 7380Rs. 8200(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Printed PU Kitten Sandals</td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Sole To Soul</td>\n",
       "      <td>High-Top Platform Heeled Boots</td>\n",
       "      <td>Rs. 8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Striped Suede Flatform Heeled Boots</td>\n",
       "      <td>Rs. 8415Rs. 9900(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Formal Leather Derby</td>\n",
       "      <td>Rs. 7990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                  Product Description  \\\n",
       "0   Heel & Buckle London             Men Formal Leather Derby   \n",
       "1         ROSSO BRUNELLO          PU Block Pumps with Buckles   \n",
       "2         ROSSO BRUNELLO              Textured PU Block Pumps   \n",
       "3                Bugatti             Men Solid Formal Oxfords   \n",
       "4                Saint G            Leather Party Block Mules   \n",
       "..                   ...                                  ...   \n",
       "95                  Geox                  Women Leather Pumps   \n",
       "96        ROSSO BRUNELLO            Printed PU Kitten Sandals   \n",
       "97          Sole To Soul       High-Top Platform Heeled Boots   \n",
       "98               Saint G  Striped Suede Flatform Heeled Boots   \n",
       "99  Heel & Buckle London             Men Formal Leather Derby   \n",
       "\n",
       "                        Price  \n",
       "0                    Rs. 7990  \n",
       "1                    Rs. 7999  \n",
       "2                    Rs. 7999  \n",
       "3                    Rs. 8999  \n",
       "4   Rs. 7380Rs. 8200(10% OFF)  \n",
       "..                        ...  \n",
       "95                   Rs. 8999  \n",
       "96                   Rs. 8499  \n",
       "97                   Rs. 8900  \n",
       "98  Rs. 8415Rs. 9900(15% OFF)  \n",
       "99                   Rs. 7990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a DataFrame\n",
    "myntra = pd.DataFrame()\n",
    "myntra[\"Brand\"]=brand2[0:100]\n",
    "myntra[\"Product Description\"]=prod2[0:100]\n",
    "myntra[\"Price\"]=price2[0:100]\n",
    "myntra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b485c2",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "\n",
    "        Enter “Laptop” in the search field and then click the search icon.\n",
    "\n",
    "        Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "be386e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "amazon_url=\"https://www.amazon.in/\"\n",
    "driver.get(amazon_url)  #getting the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "fda5a6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"fdff2e653195da832640e90a0db84f44\", element=\"27d279fc-7923-44e3-8200-ca2aa33d1d98\")>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using absolute xpath searchbar is found\n",
    "search_ama = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search_ama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "887eb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_ama.send_keys(\"laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "3fddea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_on =driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_on.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "7a47b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting intel i7 cpu as filter and i9 is not found\n",
    "i7_filter =driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[4]/li[12]/span/a/div/label/i\")\n",
    "i7_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "098ff38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD IPS 400Nits Thin & Light Laptop(16GB/512GB SSD/Windows 11/Office 2021/Iris Xe Graphics/Backlit Kb/Fingerprint Reader/2Yr Warranty/Black/878gms),4ZR1F38024',\n",
       " 'ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) FHD 144Hz, Intel Core i7-11600H 11th Gen, 4GB RTX 3050 Graphics, Gaming Laptop (16GB/512GB SSD/Windows 10/Office 2019/Gray/2.3 Kg), FX566HCB-HN299TS',\n",
       " 'ASUS VivoBook 14 (2021), 14-inch (35.56 cms) FHD, Intel Core i7-1065G7 10th Gen, Thin and Light Laptop (16GB/512GB SSD/Integrated Graphics/Office 2021/Windows 11/Silver/1.6 Kg), X415JA-EK701WS']"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt=[]\n",
    "title_taags = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_taags:\n",
    "    tt.append(i.text)\n",
    "tt[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "d4e7708e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '']"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt=[]\n",
    "ratings_taags =driver.find_elements_by_xpath('//span[@class=\"a-icon-alt\"]')\n",
    "for i in ratings_taags:\n",
    "    rt.append(i.text)\n",
    "rt[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5ee13e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['83,990', '89,490', '57,490']"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp=[]\n",
    "pricee=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for i in pricee:\n",
    "    pp.append(i.text)\n",
    "pp[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "6f716a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td></td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td></td>\n",
       "      <td>89,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Ultra 3.2K Resolution Display Inte...</td>\n",
       "      <td></td>\n",
       "      <td>77,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F17 (2022), 17.3-inch (43.94 c...</td>\n",
       "      <td></td>\n",
       "      <td>1,35,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td></td>\n",
       "      <td>91,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Microsoft Surface Studio 14.4 inches Touchscre...</td>\n",
       "      <td></td>\n",
       "      <td>3,73,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td></td>\n",
       "      <td>89,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Acer Nitro 5 11th Gen Intel Core i5-...</td>\n",
       "      <td></td>\n",
       "      <td>55,992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...</td>\n",
       "      <td></td>\n",
       "      <td>87,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Rating     Price\n",
       "0  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...           83,990\n",
       "1  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...           89,490\n",
       "2  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...           57,490\n",
       "3  Mi Notebook Ultra 3.2K Resolution Display Inte...           77,499\n",
       "4  ASUS TUF Gaming F17 (2022), 17.3-inch (43.94 c...         1,35,990\n",
       "5  HP Pavilion x360 11th Gen Intel Core i7 14 inc...           91,800\n",
       "6  Microsoft Surface Studio 14.4 inches Touchscre...         3,73,999\n",
       "7  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...           89,490\n",
       "8  (Renewed) Acer Nitro 5 11th Gen Intel Core i5-...           55,992\n",
       "9  Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...           87,990"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "amazon = pd.DataFrame()\n",
    "amazon[\"Product Name\"]=tt[0:10]\n",
    "amazon[\"Rating\"]=rt[0:10]\n",
    "amazon[\"Price\"]=pp[0:10]\n",
    "amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14a661",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location.\n",
    "    \n",
    "    You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "    \n",
    "    This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9313ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669642ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ambitionbox.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630b28f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"e97b28d49e664620bbc86ab7c28df151\", element=\"ef17103e-645d-4856-832b-f88c15320789\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clicking on the Jobs option on the homepage\n",
    "jobs_click = driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[6]\")\n",
    "jobs_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a88a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b54c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button(absolute xpath)\n",
    "ds_search = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input\")\n",
    "ds_search.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a5b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_but = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div/div/div/button/span\")\n",
    "ds_but.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6150df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in place of “Search location” enter “Noida” and select location “Noida” from drop down.\n",
    "loc_click = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\")\n",
    "loc_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aed98f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_enter = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "loc_enter.send_keys(\"Noida\")  #entering the search location as noida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce154ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"e97b28d49e664620bbc86ab7c28df151\", element=\"76fe7f17-5912-4719-8612-0cb6b878636f\")>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_radio = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/input\")\n",
    "click_radio   #finding the radio element tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46bbb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_radio.click()  #clicking  radio buttom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd7f3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping company name, No. of days ago when job was posted, Rating of the company by relative xpath\n",
    "comp_name = driver.find_elements_by_xpath('//a[@class=\"title noclick\"]')\n",
    "company_names=[]\n",
    "days_ago = driver.find_elements_by_xpath('//span[@class=\"body-small-l\"]')\n",
    "days_agoo = []\n",
    "rating_cp = driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "rating_company = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7bb0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in comp_name:\n",
    "    company_names.append(i.text)\n",
    "for i in days_ago:\n",
    "    days_agoo.append(i.text)\n",
    "for i in rating_cp:\n",
    "    rating_company.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91816fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9d ago',\n",
       " '10d ago',\n",
       " '10d ago',\n",
       " '21d ago',\n",
       " '18d ago',\n",
       " '8d ago',\n",
       " '25d ago',\n",
       " '3d ago',\n",
       " '10d ago',\n",
       " '1mon ago']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slicing the elements in intervalk of 2\n",
    "post_p = days_agoo[::2]\n",
    "post_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80664970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the requried dataframe for first 10 jobs\n",
    "a_box = pd.DataFrame()\n",
    "a_box[\"Name\"]=company_names\n",
    "a_box[\"Posting Period\"]=post_p\n",
    "a_box[\"Rating\"]=rating_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9def866a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Posting Period</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent Opportunity For Freshers For AI/ML, ...</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL Hiring Data Scientist (Loc: Noida / Chenna...</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist-II</td>\n",
       "      <td>21d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCL Tech Opening - Senior Data Scientist</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>8d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>25d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist with NLP &amp; Python</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Looking For Senior Data Scientist For Denave</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Posting Period Rating\n",
       "0  Excellent Opportunity For Freshers For AI/ML, ...         9d ago    3.9\n",
       "1  HCL Hiring Data Scientist (Loc: Noida / Chenna...        10d ago    3.8\n",
       "2                                     Data Scientist        10d ago    4.2\n",
       "3                                  Data Scientist-II        21d ago    4.2\n",
       "4           HCL Tech Opening - Senior Data Scientist        18d ago    3.8\n",
       "5                                     Data Scientist         8d ago    3.9\n",
       "6      Urgent Requirement || Data Scientist || Noida        25d ago    3.8\n",
       "7                   Data Scientist with NLP & Python         3d ago    3.8\n",
       "8                                     Data Scientist        10d ago    3.7\n",
       "9       Looking For Senior Data Scientist For Denave       1mon ago    4.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894600b",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "\n",
    "    You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "\n",
    "    The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22a231d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bcedc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url10 = \"https://www.ambitionbox.com/\"\n",
    "driver.get(url10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0ea78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the salaries option on the homepage\n",
    "salaries_click = driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[4]\")\n",
    "salaries_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54c3af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering data scientist in search job profile\n",
    "s_j_p = driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "s_j_p.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f968e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "82f93859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ab Inbev\\nbased on 28 salaries',\n",
       " 'ZS\\nbased on 15 salaries',\n",
       " 'Optum\\nbased on 25 salaries',\n",
       " 'Fractal Analytics\\nbased on 77 salaries',\n",
       " 'Tiger Analytics\\nbased on 33 salaries',\n",
       " 'UnitedHealth\\nbased on 52 salaries',\n",
       " 'Verizon\\nbased on 14 salaries',\n",
       " 'Ganit Business Solutions\\nbased on 13 salaries',\n",
       " 'Ericsson\\nbased on 43 salaries',\n",
       " 'Deloitte\\nbased on 57 salaries']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape company name, total salary record, average salary, minimum salary, maximum salary, experience required\n",
    "com_nm = driver.find_elements_by_xpath('//div[@class=\"name\"]')\n",
    "com_nms = []\n",
    "for i in com_nm:\n",
    "    com_nms.append(i.text)\n",
    "com_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "283e3752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sal =driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "avg_sals=[]\n",
    "for i in avg_sal:\n",
    "    avg_sals.append(i.text)\n",
    "len(avg_sals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "07978c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 15.0L',\n",
       " '₹ 25.5L',\n",
       " '₹ 9.5L',\n",
       " '₹ 20.0L',\n",
       " '₹ 11.0L',\n",
       " '₹ 21.3L',\n",
       " '₹ 9.5L',\n",
       " '₹ 22.0L',\n",
       " '₹ 8.3L',\n",
       " '₹ 20.0L',\n",
       " '₹ 8.3L',\n",
       " '₹ 20.5L',\n",
       " '₹ 10.0L',\n",
       " '₹ 21.0L',\n",
       " '₹ 8.5L',\n",
       " '₹ 15.0L',\n",
       " '₹ 5.8L',\n",
       " '₹ 24.0L',\n",
       " '₹ 6.9L',\n",
       " '₹ 23.4L']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_sal =driver.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "mmsal=[]\n",
    "for i in min_max_sal:\n",
    "    mmsal.append(i.text)\n",
    "mmsal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fd4937ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_sals = mmsal[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eb128550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 15.0L',\n",
       " '₹ 9.5L',\n",
       " '₹ 11.0L',\n",
       " '₹ 9.5L',\n",
       " '₹ 8.3L',\n",
       " '₹ 8.3L',\n",
       " '₹ 10.0L',\n",
       " '₹ 8.5L',\n",
       " '₹ 5.8L',\n",
       " '₹ 6.9L']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_sals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "40c84dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 25.5L',\n",
       " '₹ 20.0L',\n",
       " '₹ 21.3L',\n",
       " '₹ 22.0L',\n",
       " '₹ 20.0L',\n",
       " '₹ 20.5L',\n",
       " '₹ 21.0L',\n",
       " '₹ 15.0L',\n",
       " '₹ 24.0L',\n",
       " '₹ 23.4L']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxsal = mmsal[1::2]\n",
    "maxsal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "baeb3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_req = driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5ef0d978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist\\n . \\n3-4 yrs exp',\n",
       " 'Data Scientist\\n . \\n2 yrs exp',\n",
       " 'Data Scientist\\n . \\n3-4 yrs exp',\n",
       " 'Data Scientist\\n . \\n2-4 yrs exp',\n",
       " 'Data Scientist\\n . \\n3-4 yrs exp',\n",
       " 'Data Scientist\\n . \\n2-4 yrs exp',\n",
       " 'Data Scientist\\n . \\n4 yrs exp',\n",
       " 'Data Scientist\\n . \\n4 yrs exp',\n",
       " 'Data Scientist\\n . \\n3-4 yrs exp',\n",
       " 'Data Scientist\\n . \\n2-4 yrs exp']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_req=[]\n",
    "for i in exp_req:\n",
    "    ex_req.append(i.text)\n",
    "ex_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e78e1905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name &amp; Salary Record</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ab Inbev\\nbased on 28 salaries</td>\n",
       "      <td>₹ 20.3L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>Data Scientist\\n . \\n3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZS\\nbased on 15 salaries</td>\n",
       "      <td>₹ 15.3L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>Data Scientist\\n . \\n2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum\\nbased on 25 salaries</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "      <td>Data Scientist\\n . \\n3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics\\nbased on 77 salaries</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>Data Scientist\\n . \\n2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tiger Analytics\\nbased on 33 salaries</td>\n",
       "      <td>₹ 14.4L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>Data Scientist\\n . \\n3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth\\nbased on 52 salaries</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>Data Scientist\\n . \\n2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Verizon\\nbased on 14 salaries</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>Data Scientist\\n . \\n4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ganit Business Solutions\\nbased on 13 salaries</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>Data Scientist\\n . \\n4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson\\nbased on 43 salaries</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "      <td>₹ 24.0L</td>\n",
       "      <td>Data Scientist\\n . \\n3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deloitte\\nbased on 57 salaries</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "      <td>₹ 6.9L</td>\n",
       "      <td>₹ 23.4L</td>\n",
       "      <td>Data Scientist\\n . \\n2-4 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Name & Salary Record Average Salary  \\\n",
       "0                  Ab Inbev\\nbased on 28 salaries        ₹ 20.3L   \n",
       "1                        ZS\\nbased on 15 salaries        ₹ 15.3L   \n",
       "2                     Optum\\nbased on 25 salaries        ₹ 15.1L   \n",
       "3         Fractal Analytics\\nbased on 77 salaries        ₹ 15.1L   \n",
       "4           Tiger Analytics\\nbased on 33 salaries        ₹ 14.4L   \n",
       "5              UnitedHealth\\nbased on 52 salaries        ₹ 13.9L   \n",
       "6                   Verizon\\nbased on 14 salaries        ₹ 12.7L   \n",
       "7  Ganit Business Solutions\\nbased on 13 salaries        ₹ 12.4L   \n",
       "8                  Ericsson\\nbased on 43 salaries        ₹ 11.9L   \n",
       "9                  Deloitte\\nbased on 57 salaries        ₹ 11.7L   \n",
       "\n",
       "  Minimum Salary Maximum Salary               Experience Required  \n",
       "0        ₹ 15.0L        ₹ 25.5L  Data Scientist\\n . \\n3-4 yrs exp  \n",
       "1         ₹ 9.5L        ₹ 20.0L    Data Scientist\\n . \\n2 yrs exp  \n",
       "2        ₹ 11.0L        ₹ 21.3L  Data Scientist\\n . \\n3-4 yrs exp  \n",
       "3         ₹ 9.5L        ₹ 22.0L  Data Scientist\\n . \\n2-4 yrs exp  \n",
       "4         ₹ 8.3L        ₹ 20.0L  Data Scientist\\n . \\n3-4 yrs exp  \n",
       "5         ₹ 8.3L        ₹ 20.5L  Data Scientist\\n . \\n2-4 yrs exp  \n",
       "6        ₹ 10.0L        ₹ 21.0L    Data Scientist\\n . \\n4 yrs exp  \n",
       "7         ₹ 8.5L        ₹ 15.0L    Data Scientist\\n . \\n4 yrs exp  \n",
       "8         ₹ 5.8L        ₹ 24.0L  Data Scientist\\n . \\n3-4 yrs exp  \n",
       "9         ₹ 6.9L        ₹ 23.4L  Data Scientist\\n . \\n2-4 yrs exp  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a data frame\n",
    "ds = pd.DataFrame()\n",
    "ds[\"Company Name & Salary Record\"]=com_nms\n",
    "ds[\"Average Salary\"]=avg_sals\n",
    "ds[\"Minimum Salary\"]=mix_sals\n",
    "ds[\"Maximum Salary\"]=maxsal\n",
    "ds[\"Experience Required\"]=ex_req\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07170202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
